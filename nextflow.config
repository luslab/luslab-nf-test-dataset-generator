params {
  // Pipeline params
  mode                              = "paired" // ["single", "paired", "sra"]
  input                             = ""
  subset_count                      = 10000
  seed                              = 100

  // Boilerplate options
  outdir                            = './results'
  tracedir                          = "${params.outdir}/pipeline_info"
  publish_dir_mode                  = 'copy'
  singularity_pull_docker_container = false

  // Max resource options
  max_memory                   = '8.GB'
  max_cpus                     = 4
  max_time                     = '4.h'

  // Module params
  modules {
        'seqtk_subsample' {
            publish_dir   = 'subset'
            suffix        = '.subset'
            args          = ''
            count         = 10000
            seed          = 100
        }
   }
}

profiles {
  docker {
    docker.enabled = true
    // Avoid this error:
    //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
    // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
    // once this is established and works well, nextflow might implement this behavior as new default.
    docker.runOptions = '-u \$(id -u):\$(id -g)'
  }
  singularity {
    singularity.enabled    = true
    singularity.autoMounts = true
  }
  crick { includeConfig 'conf/crick.config' }
  test_single { includeConfig 'conf/test_single.config' }
  test_paired { includeConfig 'conf/test_paired.config' }
  test_sra    { includeConfig 'conf/test_sra.config'    }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file    = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file    = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file    = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file    = "${params.tracedir}/pipeline_dag.svg"
}

process {
  cpus = { check_max( 1, 'cpus' ) }
  memory = { check_max( 4.GB, 'memory' ) }
  time = { check_max( 2.h * task.attempt, 'time' ) }

  withLabel:process_long {
    time   = { check_max( 20.h  * task.attempt, 'time'   ) }
  }
  withLabel:error_ignore {
    errorStrategy = 'ignore'
  }
  withLabel:error_retry {
    errorStrategy = 'retry'
    maxRetries    = 2
  }
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}